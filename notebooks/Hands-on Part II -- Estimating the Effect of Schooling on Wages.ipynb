{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Estimating the Effect of Schooling on Wages: Intrumental Variables Application\n",
    "\n",
    "### Summary of Contents:\n",
    "1. [Introduction](#intro)\n",
    "2. [NLSYM Dataset](#data)\n",
    "3. [A Gentle Start: The Naive Approach](#naive)\n",
    "4. [Using Instrumental Variables: 2SLS](#2sls)\n",
    "5. [Bonus: Deep Instrumental Variables](#deepiv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction <a class=\"anchor\" id=\"intro\"></a>\n",
    "\n",
    "To measure true causal effects of a treatment $T$ on an outcome $Y$ from observational data, we need to record all features $X$ that might influence both $T$ and $Y$. These $X$'s are called confounders. \n",
    "\n",
    "When some confounders are not recorded in the data, we might get biased estimates of the treatment effect. Here is an example:\n",
    "* Children of high-income parents might attain higher levels of education (e.g. college) since they can afford it\n",
    "* Children of high-income parents might also obtain better paying jobs due to parents' connections and knowledge\n",
    "* At first sight, it might appear as if education has an effect on income, when in fact this could be fully explained by family background\n",
    "\n",
    "There are several reasons for not recording all possible confounders, such as incomplete data or a confounder that is difficult to quantify (e.g. parental involvement). However, not all is lost! In cases such as these, we can use instrumental variables $Z$, features that affect the outcome only through their effect on the treatment. \n",
    "\n",
    "In this notebook, we use a real-world problem to show how treatment effects can be extracted with the help of instrumental variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. NLSYM Dataset <a class=\"anchor\" id=\"data\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **causal impact of schooling on wages** had been studied at length. Although it is generally agreed that there is a positive impact, it is difficult to measure this effect precisely. The core problem is that education levels are not assigned at random in the population and we cannot record all possible confounders. (Think about the value parents assign to education. How would you quantify how valuable parents think their children's education is?). \n",
    "\n",
    "<img src=\"https://straubroland.files.wordpress.com/2010/12/education_technology-resized-600.png\" width=400px/>\n",
    "\n",
    "To get around this issue, we can use **proximity to a 4-year college** as an instrumental variable. Having a college nearby can allow individuals (especially low-income ones) to complete more years of education. Hence, if there was a positive treatment effect, we would expect these individuals to have higher wages on average. Note that college proximity is a valid IV since it does not affect wages directly.  \n",
    "\n",
    "We use data from the National Longitudinal Survey of Young Men (NLSYM, 1966) to estimate the average treatment effect (ATE) of education on wages (see also [Card, 1999](https://www.nber.org/papers/w4483)). The NLSYM data contains entries from men ages 14-24 that were interviewed in 1966 and again in 1976. \n",
    "\n",
    "The dataset contains the following variables:\n",
    "* $Y$ (outcome): wages (log)\n",
    "* $T$ (treatment): years of schooling\n",
    "* $Z$ (IV): proximity to a 4-year college (binary)\n",
    "* $X$ (heterogeneity): e.g. parental education\n",
    "* $W$ (controls): e.g. family composition, location, etc.\n",
    "\n",
    "The world can then be modelled as:\n",
    "$$\n",
    "\\begin{align}\n",
    "Y & = \\theta(X) \\cdot T + f(W) + \\epsilon\\\\\n",
    "T & = g(Z, W) + \\eta\n",
    "\\end{align}\n",
    "$$\n",
    "where $\\epsilon, \\eta$ are uncorrelated error terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Python imports\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "\n",
    "# EconML imports\n",
    "from econml.dml import DMLCateEstimator\n",
    "from econml.two_stage_least_squares import NonparametricTwoStageLeastSquares\n",
    "from econml.deepiv import DeepIVEstimator\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data processing\n",
    "df = pd.read_csv(\"data/card.csv\", dtype=float)\n",
    "# Filter out individuals with low education levels (outliers)\n",
    "data_filter = df['educ'].values >= 6\n",
    "# Define some variables\n",
    "T = df['educ'].values[data_filter]\n",
    "Z = df['nearc4'].values[data_filter]\n",
    "Y = df['lwage'].values[data_filter]\n",
    "\n",
    "# Impute missing values with mean, add dummy columns\n",
    "# Filter outliers (interviewees with less than 6 years of education)\n",
    "X_df = df[['exper', 'expersq']].copy()\n",
    "X_df['fatheduc'] = df['fatheduc'].fillna(value=df['fatheduc'].mean())\n",
    "X_df['fatheduc_nan'] = df['fatheduc'].isnull() * 1\n",
    "X_df['motheduc'] = df['motheduc'].fillna(value=df['motheduc'].mean())\n",
    "X_df['motheduc_nan'] = df['motheduc'].isnull() * 1\n",
    "X_df[['momdad14', 'sinmom14', 'reg661', 'reg662',\n",
    "        'reg663', 'reg664', 'reg665', 'reg666', 'reg667', 'reg668', 'reg669', 'south66']] = df[['momdad14', 'sinmom14', \n",
    "        'reg661', 'reg662','reg663', 'reg664', 'reg665', 'reg666', 'reg667', 'reg668', 'reg669', 'south66']]\n",
    "X_df[['black', 'smsa', 'south', 'smsa66']] = df[['black', 'smsa', 'south', 'smsa66']]\n",
    "columns_to_scale = ['fatheduc', 'motheduc', 'exper', 'expersq']\n",
    "# Scale continuous variables\n",
    "scaler = StandardScaler()\n",
    "X_df[columns_to_scale] = scaler.fit_transform(X_df[columns_to_scale])\n",
    "X = X_df.values[data_filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exper</th>\n",
       "      <th>expersq</th>\n",
       "      <th>fatheduc</th>\n",
       "      <th>fatheduc_nan</th>\n",
       "      <th>motheduc</th>\n",
       "      <th>motheduc_nan</th>\n",
       "      <th>momdad14</th>\n",
       "      <th>sinmom14</th>\n",
       "      <th>reg661</th>\n",
       "      <th>reg662</th>\n",
       "      <th>...</th>\n",
       "      <th>reg665</th>\n",
       "      <th>reg666</th>\n",
       "      <th>reg667</th>\n",
       "      <th>reg668</th>\n",
       "      <th>reg669</th>\n",
       "      <th>south66</th>\n",
       "      <th>black</th>\n",
       "      <th>smsa</th>\n",
       "      <th>south</th>\n",
       "      <th>smsa66</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.725159</td>\n",
       "      <td>1.896133</td>\n",
       "      <td>5.439188e-16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.034739</td>\n",
       "      <td>-0.172321</td>\n",
       "      <td>-6.134540e-01</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.786159</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.725159</td>\n",
       "      <td>1.896133</td>\n",
       "      <td>1.223740e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.553046</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.276228</td>\n",
       "      <td>0.052254</td>\n",
       "      <td>3.051432e-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0.553046</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.725159</td>\n",
       "      <td>1.896133</td>\n",
       "      <td>-6.134540e-01</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.120960</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      exper   expersq      fatheduc  fatheduc_nan  motheduc  motheduc_nan  \\\n",
       "0  1.725159  1.896133  5.439188e-16             1  0.000000             1   \n",
       "1  0.034739 -0.172321 -6.134540e-01             0 -0.786159             0   \n",
       "2  1.725159  1.896133  1.223740e+00             0  0.553046             0   \n",
       "3  0.276228  0.052254  3.051432e-01             0  0.553046             0   \n",
       "4  1.725159  1.896133 -6.134540e-01             0 -1.120960             0   \n",
       "\n",
       "   momdad14  sinmom14  reg661  reg662   ...    reg665  reg666  reg667  reg668  \\\n",
       "0       1.0       0.0     1.0     0.0   ...       0.0     0.0     0.0     0.0   \n",
       "1       1.0       0.0     1.0     0.0   ...       0.0     0.0     0.0     0.0   \n",
       "2       1.0       0.0     1.0     0.0   ...       0.0     0.0     0.0     0.0   \n",
       "3       1.0       0.0     0.0     1.0   ...       0.0     0.0     0.0     0.0   \n",
       "4       1.0       0.0     0.0     1.0   ...       0.0     0.0     0.0     0.0   \n",
       "\n",
       "   reg669  south66  black  smsa  south  smsa66  \n",
       "0     0.0      0.0    1.0   1.0    0.0     1.0  \n",
       "1     0.0      0.0    0.0   1.0    0.0     1.0  \n",
       "2     0.0      0.0    0.0   1.0    0.0     1.0  \n",
       "3     0.0      0.0    0.0   1.0    0.0     1.0  \n",
       "4     0.0      0.0    0.0   1.0    0.0     1.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore data\n",
    "X_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. A Gentle Start: The Naive Approach <a class=\"anchor\" id=\"naive\"></a>\n",
    "\n",
    "Let's assume we know nothing about instrumental variables and we want to measure the treatment effect of schooling on wages. We can apply an IV-free method like Double Machine Learning (DML) to do this and extract a treatment effect. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dml_est = DMLCateEstimator(model_y=RandomForestRegressor(n_estimators=100), \n",
    "                           model_t=RandomForestRegressor(n_estimators=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dml_est.fit(Y, T, X)\n",
    "dml_ate = dml_est.effect(X).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average treatment effect: 0.065\n"
     ]
    }
   ],
   "source": [
    "print(\"Average treatment effect: {0:.3f}\".format(dml_ate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This treatment effect is smaller than other values obtained in literature via IV. Why could that be? \n",
    "\n",
    "Because DML (like all IV-free methods) assumes that the residual errors are uncorrelated (i.e. $Y - \\hat{Y}$ is uncorrelated with $T - \\hat{T}$). Let's test this assumption:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data in 2 parts for cross-fitting \n",
    "# We do this to avoid over-fitting\n",
    "T_res, Y_res = np.zeros(T.shape[0]), np.zeros(Y.shape[0])\n",
    "kf = KFold(n_splits=2, shuffle=True)\n",
    "for train_index, test_index in kf.split(X):\n",
    "    T_res[test_index] = T[test_index] - \\\n",
    "    RandomForestRegressor(n_estimators=100).fit(X[train_index], T[train_index]).predict(X[test_index])\n",
    "    Y_res[test_index] = Y[test_index] - \\\n",
    "    RandomForestRegressor(n_estimators=100).fit(X[train_index], Y[train_index]).predict(X[test_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(T_res, Y_res)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation coefficient between T and Y errors: 0.30\n"
     ]
    }
   ],
   "source": [
    "corr_coeficient = pearsonr(T_res, Y_res)[0]\n",
    "print(\"Correlation coefficient between T and Y errors: {0:.2f}\".format(corr_coeficient))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correlation coefficient between the residuals is quite large, which means that there is some unobserved variables that affect both $T$ and $Y$. To get an accurate estimate in this case, we need to use IVs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Using Intrumental Variables: 2SLS <a class=\"anchor\" id=\"2sls\"></a>\n",
    "\n",
    "Two stage least square regression procedure (2SLS):\n",
    "1. Fit a model $T \\sim W, Z$\n",
    "2. Fit a linear model $Y \\sim \\hat{T}$ where $\\hat{T}$ is the prediction of the model in step 1.\n",
    "The coefficient from 2. above is the average treatment effect.\n",
    "\n",
    "If interested in heterogeneous treatment effects, fit a model $Y \\sim \\hat{T}\\otimes h(X)$, where $h(X)$ is a chosen featurization of the treatment effect. \n",
    "\n",
    "For more information, see the `econml` [documentation](https://econml.azurewebsites.net)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For average treatment effects, X is a column of 1s\n",
    "W = X\n",
    "Z = Z.reshape(-1, 1)\n",
    "T = T.reshape(-1, 1)\n",
    "X_ate = np.ones_like(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We apply 2SLS from the EconML library\n",
    "two_sls_est = NonparametricTwoStageLeastSquares(\n",
    "    t_featurizer=PolynomialFeatures(degree=1, include_bias=False),\n",
    "    x_featurizer=PolynomialFeatures(degree=1, include_bias=False),\n",
    "    z_featurizer=PolynomialFeatures(degree=1, include_bias=False),\n",
    "    dt_featurizer=None) # dt_featurizer only matters for marginal_effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_sls_est.fit(Y, T, X_ate, W, Z)\n",
    "two_sls_ate = two_sls_est.effect(np.ones((1,1)))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average treatment effect: 0.134\n"
     ]
    }
   ],
   "source": [
    "print(\"Average treatment effect: {0:.3f}\".format(two_sls_ate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Bonus: Deep Instrumental Variables <a class=\"anchor\" id=\"deepiv\"></a>\n",
    "\n",
    "For very flexible, but fully non-parametric IV methods, you can use neural networks for the two models in 2SLS and a mixture of gaussians for the featurizer $h(X)$. In `econml`, this method is called DeepIV. \n",
    "\n",
    "The NLSYM dataset is small (on neural net scale) so applying DeepIV is a bit of a stretch. Nevertheless, we apply DeepIV the NLSYM data as an example. You should not read too much into the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define treatment model, T ~ X, Z\n",
    "treatment_model = keras.Sequential([keras.layers.Dense(64, activation='relu', input_shape=(X.shape[1] + 1,)),\n",
    "                                    keras.layers.Dropout(rate=0.17),\n",
    "                                    keras.layers.Dense(32, activation='relu'),\n",
    "                                    keras.layers.Dropout(rate=0.17),\n",
    "                                    keras.layers.Dense(1)])\n",
    "# Define outcome model, Y ~ T_hat, X\n",
    "response_model = keras.Sequential([keras.layers.Dense(64, activation='relu', input_shape=(X.shape[1] + 1,)),\n",
    "                                   keras.layers.Dropout(rate=0.17),\n",
    "                                   keras.layers.Dense(32, activation='relu'),\n",
    "                                   keras.layers.Dropout(rate=0.17),\n",
    "                                   keras.layers.Dense(1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_fit_options = { \"epochs\": 30,\n",
    "                      \"validation_split\": 0.3,\n",
    "                      \"callbacks\": [keras.callbacks.EarlyStopping(patience=2, restore_best_weights=True)]}\n",
    "\n",
    "deepIvEst = DeepIVEstimator(n_components = 10, # number of gaussians in our mixture density network\n",
    "                            m = lambda z, x : treatment_model(keras.layers.concatenate([z,x])), # treatment model\n",
    "                            h = lambda t, x : response_model(keras.layers.concatenate([t,x])),  # response model\n",
    "                            n_samples = 1, # number of samples to use to estimate the response\n",
    "                            use_upper_bound_loss = False, # whether to use an approximation to the true loss\n",
    "                            n_gradient_samples = 1, # number of samples to use in second estimate of the response (to make loss estimate unbiased)\n",
    "                            optimizer='adam', # Keras optimizer to use for training - see https://keras.io/optimizers/ \n",
    "                            first_stage_options = keras_fit_options, # options for training treatment model\n",
    "                            second_stage_options = keras_fit_options) # options for training response model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\moprescu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 2093 samples, validate on 898 samples\n",
      "Epoch 1/30\n",
      "2093/2093 [==============================] - 1s 654us/step - loss: 23.8329 - val_loss: 5.9042\n",
      "Epoch 2/30\n",
      "2093/2093 [==============================] - 0s 95us/step - loss: 5.0409 - val_loss: 3.9612\n",
      "Epoch 3/30\n",
      "2093/2093 [==============================] - 0s 118us/step - loss: 3.8898 - val_loss: 3.4648\n",
      "Epoch 4/30\n",
      "2093/2093 [==============================] - 0s 116us/step - loss: 3.5212 - val_loss: 3.2288\n",
      "Epoch 5/30\n",
      "2093/2093 [==============================] - 0s 118us/step - loss: 3.3116 - val_loss: 3.0616\n",
      "Epoch 6/30\n",
      "2093/2093 [==============================] - 0s 77us/step - loss: 3.1305 - val_loss: 2.9131\n",
      "Epoch 7/30\n",
      "2093/2093 [==============================] - 0s 118us/step - loss: 2.9753 - val_loss: 2.7573\n",
      "Epoch 8/30\n",
      "2093/2093 [==============================] - 0s 116us/step - loss: 2.8158 - val_loss: 2.5689\n",
      "Epoch 9/30\n",
      "2093/2093 [==============================] - 0s 111us/step - loss: 2.5800 - val_loss: 2.2856\n",
      "Epoch 10/30\n",
      "2093/2093 [==============================] - 0s 112us/step - loss: 2.2167 - val_loss: 1.7570\n",
      "Epoch 11/30\n",
      "2093/2093 [==============================] - 0s 114us/step - loss: 1.7293 - val_loss: 1.4546\n",
      "Epoch 12/30\n",
      "2093/2093 [==============================] - 0s 110us/step - loss: 1.6448 - val_loss: 1.4081\n",
      "Epoch 13/30\n",
      "2093/2093 [==============================] - 0s 113us/step - loss: 1.6269 - val_loss: 1.4076\n",
      "Epoch 14/30\n",
      "2093/2093 [==============================] - 0s 117us/step - loss: 1.5911 - val_loss: 1.3996\n",
      "Epoch 15/30\n",
      "2093/2093 [==============================] - 0s 87us/step - loss: 1.5620 - val_loss: 1.3765\n",
      "Epoch 16/30\n",
      "2093/2093 [==============================] - 0s 119us/step - loss: 1.5518 - val_loss: 1.3627\n",
      "Epoch 17/30\n",
      "2093/2093 [==============================] - 0s 110us/step - loss: 1.5245 - val_loss: 1.3463\n",
      "Epoch 18/30\n",
      "2093/2093 [==============================] - 0s 110us/step - loss: 1.4822 - val_loss: 1.3022\n",
      "Epoch 19/30\n",
      "2093/2093 [==============================] - 0s 113us/step - loss: 1.5112 - val_loss: 1.3304\n",
      "Epoch 20/30\n",
      "2093/2093 [==============================] - 0s 108us/step - loss: 1.5124 - val_loss: 1.3415\n",
      "Train on 2093 samples, validate on 898 samples\n",
      "Epoch 1/30\n",
      "2093/2093 [==============================] - 3s 1ms/step - loss: 9.3704 - val_loss: 1.8564\n",
      "Epoch 2/30\n",
      "2093/2093 [==============================] - 0s 166us/step - loss: 5.7598 - val_loss: 8.5731\n",
      "Epoch 3/30\n",
      "2093/2093 [==============================] - 0s 164us/step - loss: 5.2696 - val_loss: 1.6304\n",
      "Epoch 4/30\n",
      "2093/2093 [==============================] - 0s 167us/step - loss: 34.8642 - val_loss: 1.8287\n",
      "Epoch 5/30\n",
      "2093/2093 [==============================] - 0s 168us/step - loss: 5.5516 - val_loss: 564.5439\n"
     ]
    }
   ],
   "source": [
    "deepIvEst.fit(Y, T, X, Z)\n",
    "deepIv_effect = deepIvEst.effect(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average treatment effect: 0.191\n"
     ]
    }
   ],
   "source": [
    "print(\"Average treatment effect: {0:.3f}\".format(deepIv_effect.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Heterogeneity of treatment effects\n",
    "plt.hist(deepIv_effect)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
